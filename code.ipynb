# Import Necessary Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix
from imblearn.over_sampling import SMOTE
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras import regularizers


# Load the dataset
df = pd.read_csv('/kaggle/input/dataset/online_advertising_performance_data.csv')

# Drop Unnecessary Columns
df = df.drop(columns=['Unnamed: 12', 'Unnamed: 13'], errors='ignore')

# Handle Missing Values
num_cols = ['displays', 'cost', 'clicks', 'revenue', 'post_click_conversions', 'post_click_sales_amount']
cat_cols = ['month', 'campaign_number', 'user_engagement', 'banner', 'placement']

# Impute numerical columns with mean
num_imputer = SimpleImputer(strategy='mean')
df[num_cols] = num_imputer.fit_transform(df[num_cols])

# Impute categorical columns with the most frequent value
cat_imputer = SimpleImputer(strategy='most_frequent')
df[cat_cols] = cat_imputer.fit_transform(df[cat_cols])

# Check Class Distribution
plt.hist(df['post_click_sales_amount'], bins=2)
plt.xticks([0, 1])
plt.title("Class Distribution Before Balancing")
plt.show()

# Convert Target Variable to Binary Classification
df['post_click_sales_amount'] = (df['post_click_sales_amount'] > 0).astype(int)  # 1 if sales > 0, else 0

# One-Hot Encode Categorical Variables
df = pd.get_dummies(df, columns=cat_cols, drop_first=True)

# Define Features (X) and Target Variable (y)
X = df.drop(columns=['post_click_sales_amount'])  # Features
y = df['post_click_sales_amount']  # Target Variable

# Train-Test Split (Stratified for Class Balance)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Handle Class Imbalance with SMOTE
smote = SMOTE(random_state=42)
X_train, y_train = smote.fit_resample(X_train, y_train)

# Normalize the Features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Build the Neural Network
model = Sequential([
    Input(shape=(X_train.shape[1],)),  # Input Layer
    Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)),  
    BatchNormalization(),
    Dropout(0.5),
    
    Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
    BatchNormalization(),
    Dropout(0.5),
    
    Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
    Dense(1, activation='sigmoid')  # Sigmoid for binary classification
])
